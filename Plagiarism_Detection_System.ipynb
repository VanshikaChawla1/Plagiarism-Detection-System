{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Nl8LEN-45_dy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpBEnzUX6UvA",
        "outputId": "87191a13-dbe5-4d64-d9a5-cd495e5e11de"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "    # Tokenization and lowercasing\n",
        "    words = nltk.word_tokenize(text.lower())\n",
        "\n",
        "    # Remove stop words\n",
        "    stopwords = set(nltk.corpus.stopwords.words('english'))\n",
        "    words = [word for word in words if word.isalnum() and word not in stopwords]\n",
        "\n",
        "    return ' '.join(words)"
      ],
      "metadata": {
        "id": "TpG35HWP6XdY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_plagiarism(base_doc, docs):\n",
        "    # Preprocess all documents\n",
        "    processed_docs = [preprocess(base_doc)] + [preprocess(doc) for doc in docs]\n",
        "\n",
        "    # Convert documents to TF-IDF features\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform(processed_docs)\n",
        "\n",
        "    # Calculate cosine similarities\n",
        "    similarity_scores = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:])\n",
        "\n",
        "    return similarity_scores.flatten()"
      ],
      "metadata": {
        "id": "BViOK61Z6gqg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Example base document\n",
        "    base_document = \"\"\"\n",
        "    Plagiarism is the representation of another author's language, thoughts, ideas, or expressions as one's own original work.\n",
        "    \"\"\"\n",
        "\n",
        "    # Example document repository\n",
        "    documents = [\n",
        "        \"\"\"\n",
        "        Plagiarism involves taking someone else's work or ideas and passing them off as your own.\n",
        "        \"\"\",\n",
        "        \"\"\"\n",
        "        Representing someone else's writing or ideas as your own is considered plagiarism and is unethical.\n",
        "        \"\"\",\n",
        "        \"\"\"\n",
        "        This document talks about something entirely unrelated to plagiarism.\n",
        "        \"\"\",\n",
        "        \"\"\"\n",
        "        Plagiarism is the representation of another author's language, thoughts, ideas, or expressions as one's own original work.\n",
        "        \"\"\"\n",
        "    ]\n",
        "\n",
        "    # Check for plagiarism\n",
        "    scores = check_plagiarism(base_document, documents)\n",
        "\n",
        "    # Display results\n",
        "    for i, score in enumerate(scores):\n",
        "        print(f\"Document {i+1} Similarity: {score:.2f}\")\n",
        "        if score > 0.8:\n",
        "            print(\" - Highly similar (potential plagiarism).\")\n",
        "        elif score > 0.5:\n",
        "            print(\" - Some similarities detected.\")\n",
        "        else:\n",
        "            print(\" - Not similar.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVVnj3N86nBE",
        "outputId": "5e85543a-8419-4e37-b777-b3679b7f1180"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document 1 Similarity: 0.17\n",
            " - Not similar.\n",
            "Document 2 Similarity: 0.09\n",
            " - Not similar.\n",
            "Document 3 Similarity: 0.04\n",
            " - Not similar.\n",
            "Document 4 Similarity: 1.00\n",
            " - Highly similar (potential plagiarism).\n"
          ]
        }
      ]
    }
  ]
}